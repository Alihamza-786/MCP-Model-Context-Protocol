{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f98963a-7736-4844-94b0-5d57cabe0fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import arxiv\n",
    "import json\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from typing import List\n",
    "from openai import OpenAI\n",
    "load_dotenv()\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "def process_query(query):\n",
    "    messages = [{'role': 'user', 'content': query}]\n",
    "    process_loop = True\n",
    "\n",
    "    while process_loop:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=messages,\n",
    "            tools=tools,\n",
    "            tool_choice=\"auto\",\n",
    "            max_tokens=2024\n",
    "        )\n",
    "\n",
    "        reply = response.choices[0].message\n",
    "        tool_calls = reply.tool_calls\n",
    "\n",
    "        if tool_calls:\n",
    "            messages.append(reply)  # assistant tool call message\n",
    "\n",
    "            for tool_call in tool_calls:\n",
    "                tool_name = tool_call.function.name\n",
    "                tool_args = json.loads(tool_call.function.arguments)\n",
    "                tool_id = tool_call.id\n",
    "\n",
    "                print(f\"\\nðŸ›  Calling tool {tool_name} with args {tool_args}\")\n",
    "\n",
    "                result = execute_tool(tool_name, tool_args)\n",
    "\n",
    "                messages.append({\n",
    "                    \"role\": \"tool\",\n",
    "                    \"tool_call_id\": tool_id,\n",
    "                    \"content\": result\n",
    "                })\n",
    "        else:\n",
    "            print(f\"\\nðŸ¤– Assistant: {reply.content}\")\n",
    "            messages.append(reply)\n",
    "            process_loop = False\n",
    "\n",
    "def chat_loop():\n",
    "    print(\"Type your queries or 'quit' to exit.\")\n",
    "    while True:\n",
    "        try:\n",
    "            query = input(\"\\nQuery: \").strip()\n",
    "            if query.lower() == 'quit':\n",
    "                break\n",
    "    \n",
    "            process_query(query)\n",
    "            print(\"\\n\")\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError: {str(e)}\")\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41490be-0f28-46e0-955b-35dcdcbbe530",
   "metadata": {},
   "source": [
    "# Building Your MCP Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec36e5c6-e499-4665-be5b-7266e9e8aaf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mcp import ClientSession, StdioServerParameters, types\n",
    "from mcp.client.stdio import stdio_client\n",
    "\n",
    "# Create server parameters for stdio connection\n",
    "server_params = StdioServerParameters(\n",
    "    command=\"uv\",  # Executable\n",
    "    args=[\"run example_server.py\"],  # Command line arguments\n",
    "    env=None,  # Optional environment variables\n",
    ")\n",
    "\n",
    "async def run():\n",
    "    # Launch the server as a subprocess & returns the read and write streams\n",
    "    # read: the stream that the client will use to read msgs from the server\n",
    "    # write: the stream that client will use to write msgs to the server\n",
    "    async with stdio_client(server_params) as (read, write): \n",
    "        # the client session is used to initiate the connection \n",
    "        # and send requests to server \n",
    "        async with ClientSession(read, write) as session:\n",
    "            # Initialize the connection (1:1 connection with the server)\n",
    "            await session.initialize()\n",
    "\n",
    "            # List available tools\n",
    "            tools = await session.list_tools()\n",
    "\n",
    "            # will call the chat_loop here\n",
    "            # ....\n",
    "            \n",
    "            # Call a tool: this will be in the process_query method\n",
    "            result = await session.call_tool(\"tool-name\", arguments={\"arg1\": \"value\"})\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(run())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e41dc92-b204-4c6e-83ef-b244e87ca029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mcp_project/mcp_chatbot.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mcp_project/mcp_chatbot.py\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from mcp import ClientSession, StdioServerParameters, types\n",
    "from mcp.client.stdio import stdio_client\n",
    "from typing import List\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "import os\n",
    "import json\n",
    "nest_asyncio.apply()\n",
    "load_dotenv()\n",
    "from openai import OpenAI\n",
    "\n",
    "class MCP_ChatBot:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.session: ClientSession = None\n",
    "        self.client = OpenAI()  # OpenAI client\n",
    "        self.available_tools: List[dict] = []\n",
    "\n",
    "    async def process_query(self, query):\n",
    "        messages = [{'role': 'user', 'content': query}]\n",
    "        process_query = True\n",
    "\n",
    "        while process_query:\n",
    "            # Send query to OpenAI\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=\"gpt-4o-mini\",\n",
    "                messages=messages,\n",
    "                tools=self.available_tools,\n",
    "                max_tokens=2024\n",
    "            )\n",
    "\n",
    "            message = response.choices[0].message\n",
    "            tool_calls = getattr(message, \"tool_calls\", None)\n",
    "\n",
    "            if tool_calls:\n",
    "                # If tool call(s) requested\n",
    "                for tool_call in tool_calls:\n",
    "                    tool_name = tool_call.function.name\n",
    "                    tool_args = json.loads(tool_call.function.arguments)\n",
    "                    tool_id = tool_call.id\n",
    "\n",
    "                    print(f\"Calling tool {tool_name} with args {tool_args}\")\n",
    "\n",
    "                    # Tool call through session\n",
    "                    result = await self.session.call_tool(tool_name, arguments=tool_args)\n",
    "\n",
    "                    # Append tool call + tool result to messages\n",
    "                    messages.append({\n",
    "                        \"role\": \"assistant\",\n",
    "                        \"tool_calls\": [tool_call.model_dump()]  # Needed for follow-up\n",
    "                    })\n",
    "                    messages.append({\n",
    "                        \"role\": \"tool\",\n",
    "                        \"tool_call_id\": tool_id,\n",
    "                        \"content\": result.content\n",
    "                    })\n",
    "\n",
    "            else:\n",
    "                # If it's just a text response\n",
    "                print(message.content)\n",
    "                process_query = False\n",
    "\n",
    "                        \n",
    "    async def chat_loop(self):\n",
    "        \"\"\"Run an interactive chat loop\"\"\"\n",
    "        print(\"\\nMCP Chatbot Started!\")\n",
    "        print(\"Type your queries or 'quit' to exit.\")\n",
    "\n",
    "        while True:\n",
    "            try:\n",
    "                query = input('\\nQuery: ').strip()\n",
    "                if query.lower() == 'quit':\n",
    "                    break\n",
    "                await self.process_query(query)\n",
    "                print('\\n')\n",
    "            except Exception as e:\n",
    "                print(f'\\nError: {str(e)}')\n",
    "                \n",
    "    async def connect_to_server_and_run(self):\n",
    "        server_params = StdioServerParameters(\n",
    "            command='uv',\n",
    "            args=['run', 'research_server.py'],\n",
    "            env=None,\n",
    "        )\n",
    "        async with stdio_client(server_params) as (read, write):\n",
    "            async with ClientSession(read, write) as session:\n",
    "                self.session = session\n",
    "                await session.initialize()\n",
    "                response = await session.list_tools()\n",
    "                tools = response.tools\n",
    "                print('\\nConnected to server with tools:', [tool.name for tool in tools])\n",
    "\n",
    "                self.available_tools = [{\n",
    "                    'type': 'function',\n",
    "                    'function': {\n",
    "                    'name': tool.name,\n",
    "                    'description': tool.description,\n",
    "                    'parameters': tool.inputSchema\n",
    "                    }\n",
    "                } for tool in response.tools]\n",
    "\n",
    "                await self.chat_loop()\n",
    "        \n",
    "async def main():\n",
    "    chatbot = MCP_ChatBot()\n",
    "    await chatbot.connect_to_server_and_run()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8d86144-3228-4449-995e-48a0a4db4262",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"600\"\n",
       "            height=\"768\"\n",
       "            src=\"http://localhost:8888/terminals/2\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7a3f979b9ac0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# start a new terminal\n",
    "import os\n",
    "from IPython.display import IFrame\n",
    "\n",
    "IFrame(\"http://localhost:8888/terminals/2\", width=600, height=768)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8a662f-4e80-4e0a-82d8-36cb63a39388",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
